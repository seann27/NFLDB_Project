# activate environment
$ workon py1

##### Script inventory includes: #####
- scraper for fantasypros.com
- scraper for espn projections
- scraper for espn weekly stats
- scraper for basic pro-football reference data
- SQL database with tables for each dataset being scraped
	- separate tables for defensive stats
- GA algorithm which uses espn point projections vs draft kings salaries for optimization
- weekly stat data for players uses a year-week-name-position-team as the id.

##### Build a better functioning database: #####
- for starters, scrape all game data from pro-footballreference
	- have a game table which has gameids
		- season
		- week
		- home team
		- home record
		- home points
		- away team
		- away record
		- away points
		- odds
			- edit script so that only scrapes 1 season at a time
			- add team records
			- edit debugging statements to only print errors
			- update ATS metrics
	- have a player and team tables which have general info
		- playerid
		- espnid
		- name
		- age
		- years in league
		- status
			- active/inactive/injured
	- instead of weekly rankings, have offense/defense tables
		- uniqueid
		- playerid
		- gameid
		- player's team
		- opp team
		- snapcount
		- stats
		- fantasy points
	- set up offense/defense projections similar to table above
	- might be prudent to have an injury table
		- playerid
		- gameid
		- status
		* this table will be hard to rely on for older datasets, might need to supplement with snapcounts
	- play by play tables
		- gameid
		- offensive team
		- defensive team
		- offensive points
		- defensive points
		- offensive timeouts
		- defensive timeouts
		- quarter
		- time left (in quarter)
		- down
		- yards to go
		- fieldzone
			- 5 Possible values: 1 = Own 0 - 20 Yard Line, 2 = Own 21 - 40, 3 = Midfield, 4 = Opponent's 21 - 40, 5 = Red Zone
		- type
			- run,pass,FG,punt
		- yardage
		- outcome
			- sack,penalty,interception,fumble,safety,block,off_td,def_td
- need a pipeline for scraping and archiving historical data
	- should use scraping modules
	- should be robust enough to have modules added to it and rerun
		- new data types
- need a pipeline for scraping new data (which can be run every week)


##### Analyze dataset above: #####
- player matchmaking stats table
	* experimental table which will hold calculated values from dataset above
	* will use these values to assess the accuracy of espn projections
	- implement some machine learning prinicples to aid in this table
- Use these analytic tables to filter the data for the GA algorithm
- Success will be draftkings lineups which consistently score >150 points per game
	- with any luck, might be able to bump this to >160
		- if not, could alternatively use different site for player predictions

##### Design a simple web-interface: #####
- use django framework
- incorporate javascript components

/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
/\/\/\/\/\/\/\/\/\ Technical Details /\/\/\/\/\/\/\/\/\
/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/

- should think about keeping SQL statements in separate files and executing them within a
script or set of scripts (pipeline)
	- use a helper function, have it take in *args,*kwargs

- need to have opponent column in offense/defense database
- move pass_tds to be in line with other pass metrics in db
- decided not to do an insert/update on offensive playerdb, going to go for a one time insertion.
	- cleaner code
	- can have autoincremented PK
	- need to change table structure to autoincremented PK for this table

- need to add st louis rams, san diego chargers to profootball reference abbrev
- change the way everything is scraped:
	- first scrape snapcounts -> create dictionaries of both offensive and defensive players
	- then scrape play-by-plays, inserting into db and updating the player objects
	- update final player objects at end of scraping play-by-play
	- assess summary tables for accuracy
	- this might be faster than scraping multiple tables on page

############ play by play syntax ###########
- YARDS    = x
- KICKOFF  = <player> kicks off [x] yards, [RETURN]/touchback
- RUN 	   = <player> up the middle, right/left guard/end/tackle for x yards [TACKLE/SACK/FUMBLE]
- TACKLE   = (tackle by <player> and <player>)
- SACK     = <player> sacked by <player> for [x] yards
- FUMBLE   = <player> fumbles, (forced by <player>),recovered by <player> [RETURN][TACKLE]
- PASS     = <player> pass complete/incomplete short/deep left/right/middle to/intended for <player> for [x] yards [TACKLE/PASS DEF]
- PASS DEF = (defended by <player>)
- INT      = [PASS] is intercepted by <player> at location and [RETURN]
- RETURN   = returned by <player> for [x] yards
- MISC     = Timeout #[x] by <team>
- XP KICK  = <player> kicks extra point good/no good
- PUNT     = <player> punts [x] yards, (blank)/out of bounds/[RETURN][RUN DEF]/fair catch by <player>
- CHAL     = <team abbrev> challenged ... and play was upheld/overturned
- KNEEL    = <player> kneels for [x] yards
- PENALTY  = Penalty on <player> ... [x] yards (blank)/no play/Declined

^^ construct pattern matches to certain play phrases

pseudocode:

play.split(' ')	# split play into words
action = ''
play_components = []
for word in play:
	action .= word
	if action matches regex expression for play phrase patterns (above):
		push play_components(action)	# add action to play list
		process flags					# actions have flags (no gain,turnover,touchdown,penalty,no play)
		action = ''	# reset phrase string

analyze play components based on flags:
	insert into rush/pass tables with result flag (gain,no gain,turnover,penalty[off/def]/yards)
	insert into dst table with result flag (tackle,defended,int,fum,gain,loss,penalty)
	insert into penalty table if penalty enforced()
	insert into special teams table if special teams play
