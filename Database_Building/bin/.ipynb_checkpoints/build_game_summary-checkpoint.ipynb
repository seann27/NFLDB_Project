{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up database connections . . .\n",
      "Reading db csv file . . .\n",
      "Dropping unused columns . . .\n",
      "Generating odds metrics for gameinfo table . . .\n",
      "Getting gameids from nfl_api . . .\n",
      "Grabbing the matching pro-football-reference.com game links for each game . . .\n",
      "\tScraping  2009 - 1  . . .\n",
      "\tScraping  2009 - 2  . . .\n",
      "\tScraping  2009 - 3  . . .\n",
      "\tScraping  2009 - 4  . . .\n",
      "\tScraping  2009 - 5  . . .\n",
      "\tScraping  2009 - 6  . . .\n",
      "\tScraping  2009 - 7  . . .\n",
      "\tScraping  2009 - 8  . . .\n",
      "\tScraping  2009 - 9  . . .\n",
      "\tScraping  2009 - 10  . . .\n",
      "\tScraping  2009 - 11  . . .\n",
      "\tScraping  2009 - 12  . . .\n",
      "\tScraping  2009 - 13  . . .\n",
      "\tScraping  2009 - 14  . . .\n",
      "\tScraping  2009 - 15  . . .\n",
      "\tScraping  2009 - 16  . . .\n",
      "\tScraping  2009 - 17  . . .\n",
      "\tScraping  2010 - 1  . . .\n",
      "\tScraping  2010 - 2  . . .\n",
      "\tScraping  2010 - 3  . . .\n",
      "\tScraping  2010 - 4  . . .\n",
      "\tScraping  2010 - 5  . . .\n",
      "\tScraping  2010 - 6  . . .\n",
      "\tScraping  2010 - 7  . . .\n",
      "\tScraping  2010 - 8  . . .\n",
      "\tScraping  2010 - 9  . . .\n",
      "\tScraping  2010 - 10  . . .\n",
      "\tScraping  2010 - 11  . . .\n",
      "\tScraping  2010 - 12  . . .\n",
      "\tScraping  2010 - 13  . . .\n",
      "\tScraping  2010 - 14  . . .\n",
      "\tScraping  2010 - 15  . . .\n",
      "\tScraping  2010 - 16  . . .\n",
      "\tScraping  2010 - 17  . . .\n",
      "\tScraping  2011 - 1  . . .\n",
      "\tScraping  2011 - 2  . . .\n",
      "\tScraping  2011 - 3  . . .\n",
      "\tScraping  2011 - 4  . . .\n",
      "\tScraping  2011 - 5  . . .\n",
      "\tScraping  2011 - 6  . . .\n",
      "\tScraping  2011 - 7  . . .\n",
      "\tScraping  2011 - 8  . . .\n",
      "\tScraping  2011 - 9  . . .\n",
      "\tScraping  2011 - 10  . . .\n",
      "\tScraping  2011 - 11  . . .\n",
      "\tScraping  2011 - 12  . . .\n",
      "\tScraping  2011 - 13  . . .\n",
      "\tScraping  2011 - 14  . . .\n",
      "\tScraping  2011 - 15  . . .\n",
      "\tScraping  2011 - 16  . . .\n",
      "\tScraping  2011 - 17  . . .\n",
      "\tScraping  2012 - 1  . . .\n",
      "\tScraping  2012 - 2  . . .\n",
      "\tScraping  2012 - 3  . . .\n",
      "\tScraping  2012 - 4  . . .\n",
      "\tScraping  2012 - 5  . . .\n",
      "\tScraping  2012 - 6  . . .\n",
      "\tScraping  2012 - 7  . . .\n",
      "\tScraping  2012 - 8  . . .\n",
      "\tScraping  2012 - 9  . . .\n",
      "\tScraping  2012 - 10  . . .\n",
      "\tScraping  2012 - 11  . . .\n",
      "\tScraping  2012 - 12  . . .\n",
      "\tScraping  2012 - 13  . . .\n",
      "\tScraping  2012 - 14  . . .\n",
      "\tScraping  2012 - 15  . . .\n",
      "\tScraping  2012 - 16  . . .\n",
      "\tScraping  2012 - 17  . . .\n",
      "\tScraping  2013 - 1  . . .\n",
      "\tScraping  2013 - 2  . . .\n",
      "\tScraping  2013 - 3  . . .\n",
      "\tScraping  2013 - 4  . . .\n",
      "\tScraping  2013 - 5  . . .\n",
      "\tScraping  2013 - 6  . . .\n",
      "\tScraping  2013 - 7  . . .\n",
      "\tScraping  2013 - 8  . . .\n",
      "\tScraping  2013 - 9  . . .\n",
      "\tScraping  2013 - 10  . . .\n",
      "\tScraping  2013 - 11  . . .\n",
      "\tScraping  2013 - 12  . . .\n",
      "\tScraping  2013 - 13  . . .\n",
      "\tScraping  2013 - 14  . . .\n",
      "\tScraping  2013 - 15  . . .\n",
      "\tScraping  2013 - 16  . . .\n",
      "\tScraping  2013 - 17  . . .\n",
      "\tScraping  2014 - 1  . . .\n",
      "\tScraping  2014 - 2  . . .\n",
      "\tScraping  2014 - 3  . . .\n",
      "\tScraping  2014 - 4  . . .\n",
      "\tScraping  2014 - 5  . . .\n",
      "\tScraping  2014 - 6  . . .\n",
      "\tScraping  2014 - 7  . . .\n",
      "\tScraping  2014 - 8  . . .\n",
      "\tScraping  2014 - 9  . . .\n",
      "\tScraping  2014 - 10  . . .\n",
      "\tScraping  2014 - 11  . . .\n",
      "\tScraping  2014 - 12  . . .\n",
      "\tScraping  2014 - 13  . . .\n",
      "\tScraping  2014 - 14  . . .\n",
      "\tScraping  2014 - 15  . . .\n",
      "\tScraping  2014 - 16  . . .\n",
      "\tScraping  2014 - 17  . . .\n",
      "\tScraping  2015 - 1  . . .\n",
      "\tScraping  2015 - 2  . . .\n",
      "\tScraping  2015 - 3  . . .\n",
      "\tScraping  2015 - 4  . . .\n",
      "\tScraping  2015 - 5  . . .\n",
      "\tScraping  2015 - 6  . . .\n",
      "\tScraping  2015 - 7  . . .\n",
      "\tScraping  2015 - 8  . . .\n",
      "\tScraping  2015 - 9  . . .\n",
      "\tScraping  2015 - 10  . . .\n",
      "\tScraping  2015 - 11  . . .\n",
      "\tScraping  2015 - 12  . . .\n",
      "\tScraping  2015 - 13  . . .\n",
      "\tScraping  2015 - 14  . . .\n",
      "\tScraping  2015 - 15  . . .\n",
      "\tScraping  2015 - 16  . . .\n",
      "\tScraping  2015 - 17  . . .\n",
      "\tScraping  2016 - 1  . . .\n",
      "\tScraping  2016 - 2  . . .\n",
      "\tScraping  2016 - 3  . . .\n",
      "\tScraping  2016 - 4  . . .\n",
      "\tScraping  2016 - 5  . . .\n",
      "\tScraping  2016 - 6  . . .\n",
      "\tScraping  2016 - 7  . . .\n",
      "\tScraping  2016 - 8  . . .\n",
      "\tScraping  2016 - 9  . . .\n",
      "\tScraping  2016 - 10  . . .\n",
      "\tScraping  2016 - 11  . . .\n",
      "\tScraping  2016 - 12  . . .\n",
      "\tScraping  2016 - 13  . . .\n",
      "\tScraping  2016 - 14  . . .\n",
      "\tScraping  2016 - 15  . . .\n",
      "\tScraping  2016 - 16  . . .\n",
      "\tScraping  2016 - 17  . . .\n",
      "\tScraping  2017 - 1  . . .\n",
      "\tScraping  2017 - 2  . . .\n",
      "\tScraping  2017 - 3  . . .\n",
      "\tScraping  2017 - 4  . . .\n",
      "\tScraping  2017 - 5  . . .\n",
      "\tScraping  2017 - 6  . . .\n",
      "\tScraping  2017 - 7  . . .\n",
      "\tScraping  2017 - 8  . . .\n",
      "\tScraping  2017 - 9  . . .\n",
      "\tScraping  2017 - 10  . . .\n",
      "\tScraping  2017 - 11  . . .\n",
      "\tScraping  2017 - 12  . . .\n",
      "\tScraping  2017 - 13  . . .\n",
      "\tScraping  2017 - 14  . . .\n",
      "\tScraping  2017 - 15  . . .\n",
      "\tScraping  2017 - 16  . . .\n",
      "\tScraping  2017 - 17  . . .\n",
      "\tScraping  2018 - 1  . . .\n",
      "\tScraping  2018 - 2  . . .\n",
      "\tScraping  2018 - 3  . . .\n",
      "\tScraping  2018 - 4  . . .\n",
      "\tScraping  2018 - 5  . . .\n",
      "\tScraping  2018 - 6  . . .\n",
      "\tScraping  2018 - 7  . . .\n",
      "\tScraping  2018 - 8  . . .\n",
      "\tScraping  2018 - 9  . . .\n",
      "\tScraping  2018 - 10  . . .\n",
      "\tScraping  2018 - 11  . . .\n",
      "\tScraping  2018 - 12  . . .\n",
      "\tScraping  2018 - 13  . . .\n",
      "\tScraping  2018 - 14  . . .\n",
      "\tScraping  2018 - 15  . . .\n",
      "\tScraping  2018 - 16  . . .\n",
      "\tScraping  2018 - 17  . . .\n",
      "(2560, 3)\n",
      "(2560, 14)\n"
     ]
    }
   ],
   "source": [
    "# import here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from sqlalchemy import create_engine\n",
    "from NFL_RefMaps import TeamDictionary\n",
    "from NFL_Metrics import SkillPoints\n",
    "from scrapers import PFR_Gamelinks,PFR_Gamepage\n",
    "\n",
    "# connect to database\n",
    "print(\"Setting up database connections . . .\")\n",
    "kaggle_engine = create_engine('mysql+pymysql://root:@localhost:3306/kaggle')\n",
    "kaggle_conn = kaggle_engine.connect()\n",
    "nfldb_engine = create_engine('mysql+pymysql://root:@localhost:3306/main_stats')\n",
    "main_engine = nfldb_engine.connect()\n",
    "file = (\"D:\\\\NFLDB\\\\game_info.csv\")\n",
    "\n",
    "# trim csv file to relevant stats for weeks 1-16, 2009-2018\n",
    "print(\"Reading db csv file . . .\")\n",
    "gameinfo = pd.read_csv(file)\n",
    "\n",
    "print(\"Dropping unused columns . . .\")\n",
    "# drop playoff weeks\n",
    "indexNames = gameinfo[ gameinfo['schedule_playoff'] == True ].index\n",
    "gameinfo.drop(indexNames,inplace=True)\n",
    "\n",
    "# drop stats older than 2009\n",
    "indexNames = gameinfo[ gameinfo['schedule_season'] < 2009 ].index\n",
    "gameinfo.drop(indexNames,inplace=True)\n",
    "\n",
    "# drop unused columns\n",
    "gameinfo.drop(['schedule_playoff'],axis=1,inplace=True)\n",
    "gameinfo.drop(['stadium'],axis=1,inplace=True)\n",
    "gameinfo.drop(['stadium_neutral'],axis=1,inplace=True)\n",
    "gameinfo.drop(['weather_temperature'],axis=1,inplace=True)\n",
    "gameinfo.drop(['weather_wind_mph'],axis=1,inplace=True)\n",
    "gameinfo.drop(['weather_humidity'],axis=1,inplace=True)\n",
    "gameinfo.drop(['weather_detail'],axis=1,inplace=True)\n",
    "\n",
    "def get_home_favorite(row):\n",
    "    home_team = row['team_home']\n",
    "    home_abbrev = TeamDictionary().nfl_api[home_team]\n",
    "    if home_abbrev == row['team_favorite_id']:\n",
    "        return 1\n",
    "    elif row['team_favorite_id'] == 'PICK':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_spread_result(row):\n",
    "    score_fav = 0\n",
    "    score_und = 0\n",
    "    spread = row['spread_favorite']*-1\n",
    "    if(row['home_favorite']==1):\n",
    "        score_fav = row['score_home']\n",
    "        score_und = row['score_away']\n",
    "    else:\n",
    "        score_fav = row['score_away']\n",
    "        score_und = row['score_home']\n",
    "    diff = score_fav-score_und\n",
    "    if( diff > spread ):\n",
    "        return 1\n",
    "    elif( diff < spread ):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_OU_result(row):\n",
    "    OU = float(row['over_under_line'])\n",
    "    total = row['score_home']+row['score_away']\n",
    "    if( total > OU ):\n",
    "        return 1\n",
    "    elif( total < OU ):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_index(row):\n",
    "    date = row['schedule_date']\n",
    "    comps = date.split('/')\n",
    "    date = comps[2]+'-'+comps[0]+'-'+comps[1]\n",
    "    return date+TeamDictionary().nfl_api[row['team_home']]\n",
    "\n",
    "# # generate metrics for dataset, set index\n",
    "print(\"Generating odds metrics for gameinfo table . . .\")\n",
    "gameinfo['home_favorite'] = gameinfo.apply (lambda row: get_home_favorite(row), axis=1)\n",
    "gameinfo['spread_result'] = gameinfo.apply(lambda row: get_spread_result(row),axis=1)\n",
    "gameinfo['OU_result'] = gameinfo.apply(lambda row: get_OU_result(row),axis=1)\n",
    "gameinfo['idx'] = gameinfo.apply(lambda row: get_index(row),axis=1)\n",
    "gameinfo.set_index('idx',inplace=True)\n",
    "\n",
    "def get_pbpindex(row):\n",
    "    team_name = row['home_team']\n",
    "    comps = row['game_date'].split('/')\n",
    "    date = comps[2]+'-'+str(comps[0]).zfill(2)+'-'+str(comps[1]).zfill(2)\n",
    "    idx = date+team_name\n",
    "    return idx\n",
    "\n",
    "def map_pfrlinks():\n",
    "    cols = ['idx','pfr_link']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    seasons = np.arange(2009,2019).tolist()\n",
    "    weeks = np.arange(1,18).tolist()\n",
    "    data = {'idx':[],'gamelinks':[],'season':[],'week':[]}\n",
    "\n",
    "    cache = os.path.exists('pfrlinks.txt')\n",
    "    cache_links = []\n",
    "    cache_indexes = {}\n",
    "    if cache:\n",
    "        cache = open('pfrlinks.txt','r')\n",
    "        games = cache.readlines()\n",
    "        for game in games:\n",
    "            comps = game.split(',')\n",
    "            link = comps[1].rstrip()\n",
    "            cache_links.append(link)\n",
    "            cache_indexes[link]=comps[0].strip()\n",
    "        cache.close()\n",
    "    file = open('pfrlinks.txt','a')\n",
    "\n",
    "    for season in seasons:\n",
    "        for week in weeks:\n",
    "            print(\"\\tScraping \",str(season),\"-\",str(week),\" . . .\")\n",
    "            pfrg = PFR_Gamelinks(season,week)\n",
    "            gamelinks = pfrg.get_game_links()\n",
    "            for game in gamelinks:\n",
    "                if(game not in cache_links):\n",
    "                    print(\"\\t\\tGame: \",game)\n",
    "                    data['gamelinks'].append(game)\n",
    "                    pfr = PFR_Gamepage(game)\n",
    "                    gameinfo = pfr.get_gameinfo()\n",
    "                    date = gameinfo[1]\n",
    "                    mm = date[4:6]\n",
    "                    yyyy = date[0:4]\n",
    "                    dd = date[6:8]\n",
    "                    date = yyyy+\"-\"+mm+\"-\"+dd\n",
    "                    home_team = gameinfo[2]\n",
    "                    teams = TeamDictionary().nfl_api\n",
    "                    data['idx'].append(date+teams[home_team])\n",
    "                    file.write(date+teams[home_team]+','+game+'\\n')\n",
    "                else:\n",
    "                    data['gamelinks'].append(game)\n",
    "                    data['idx'].append(cache_indexes[game])\n",
    "                data['season'].append(season)\n",
    "                data['week'].append(week)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df.set_index('idx',inplace=True)\n",
    "    file.close()\n",
    "    return df\n",
    "\n",
    "print(\"Getting gameids from nfl_api . . .\")\n",
    "# sql statement for getting gameids\n",
    "sql = \"select distinct(pbp.game_id) as game_id, pbp.home_team as home_team, pbp.game_date as game_date \\\n",
    "       from nfl_pbp pbp \\\n",
    "       order by pbp.game_id\"\n",
    "gameinfo_gameids = pd.read_sql_query(sql, kaggle_conn, index_col=None)\n",
    "gameinfo_gameids['idx'] = gameinfo_gameids.apply(lambda row: get_pbpindex(row),axis=1)\n",
    "\n",
    "gameinfo_gameids.set_index('idx',inplace=True)\n",
    "gameinfo['game_id']=gameinfo_gameids['game_id']\n",
    "\n",
    "print(\"Grabbing the matching pro-football-reference.com game links for each game . . .\")\n",
    "pfrlinks = map_pfrlinks()\n",
    "print(pfrlinks.shape)\n",
    "print(gameinfo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c4dc6e6f7a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgameinfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pfr_gamelinks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpfrlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gamelinks'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3606\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreindexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   3597\u001b[0m                     \u001b[1;31m# duplicate axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3598\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3599\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m                     \u001b[1;31m# other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindexer\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[1;31m# GH 4107\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3594\u001b[1;33m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3595\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m   3736\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3738\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3740\u001b[0m     def drop(self, labels=None, axis=0, index=None, columns=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4354\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4355\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 4356\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4358\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4372\u001b[0m             obj = obj._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[0;32m   4373\u001b[0m                                              \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4374\u001b[1;33m                                              copy=copy, allow_dups=False)\n\u001b[0m\u001b[0;32m   4375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4376\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4488\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4489\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4490\u001b[1;33m                                                 copy=copy)\n\u001b[0m\u001b[0;32m   4491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nfl_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3086\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3087\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3089\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "gameinfo['pfr_gamelinks'] = pfrlinks['gamelinks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
